{"cells":[{"cell_type":"markdown","metadata":{"id":"8QqJbxx-_BU7"},"source":["#Install libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54525,"status":"ok","timestamp":1677763960828,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"},"user_tz":-60},"id":"8Fy54k2O-Q3N","outputId":"65e9a8ee-80a7-46aa-dcb9-a61de1f6bca4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.4)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.8/dist-packages (1.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (2.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (4.64.1)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (1.13.1+cu116)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (0.0.53)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (1.22.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (0.1.97)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (1.26.82)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch_transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->pytorch_transformers) (4.5.0)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3->pytorch_transformers) (1.0.1)\n","Requirement already satisfied: botocore<1.30.0,>=1.29.82 in /usr/local/lib/python3.8/dist-packages (from boto3->pytorch_transformers) (1.29.82)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from boto3->pytorch_transformers) (0.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_transformers) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_transformers) (4.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->pytorch_transformers) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->pytorch_transformers) (8.1.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.82->boto3->pytorch_transformers) (2.8.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.38.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.22.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.2)\n","Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.5.3)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.3.5)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.22.4)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.7.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (4.38.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->seaborn) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n"]}],"source":["!pip install transformers\n","!pip install torch torchvision\n","!pip install pandas\n","!pip install numpy\n","!pip install datasets\n","!pip install pytorch_transformers\n","!pip install scikit-learn\n","!pip install matplotlib\n","!pip install seaborn\n","!pip install nltk"]},{"cell_type":"markdown","metadata":{"id":"J13iSqp__qMw"},"source":["Import the required libraries"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"o-shbksg4Wz2","executionInfo":{"status":"ok","timestamp":1677764093671,"user_tz":-60,"elapsed":332,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"53cb6c03-84ed-4c61-82d7-13d965fab98d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using PyTorch version: 1.13.1+cu116 Device: cpu \n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import torch\n","from torch.utils.data import (TensorDataset, DataLoader,\n","                              RandomSampler, SequentialSampler)\n","\n","from pytorch_transformers import BertTokenizer, BertConfig\n","from pytorch_transformers import BertForSequenceClassification\n","from pytorch_transformers import AdamW, WarmupLinearSchedule\n","\n","from distutils.version import LooseVersion as LV\n","\n","from sklearn.model_selection import train_test_split\n","\n","import io\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from datasets import load_dataset\n","\n","import tensorflow_datasets as tfds\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","\n","sns.set()\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    devicename = '['+torch.cuda.get_device_name(0)+']'\n","else:\n","    device = torch.device('cpu')\n","    devicename = \"\"\n","    \n","print('Using PyTorch version:', torch.__version__,\n","      'Device:', device, devicename)\n","assert(LV(torch.__version__) >= LV(\"1.0.0\"))\n"]},{"cell_type":"markdown","source":["Download the IMDb and SST-2 datasets and extract them."],"metadata":{"id":"PXhFhTFsYSGM"}},{"cell_type":"code","source":["# Load the IMDB dataset\n","imdb_dataset = load_dataset(\"imdb\")\n","\n","\n","# Load the SST-2 dataset\n","sst2_dataset = load_dataset(\"glue\", \"sst2\")"],"metadata":{"id":"S2w3DXq8zmL7","colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["885bb7cf41b843c0b8dd311a3470ea4f","7bb2fcc4a11f4318b170136d08ed8859","023d392d1eb740c68f9147860f900d14","9e9558b7ff0d419580512e75b0cd71c5","36c69c1186404946861e9e5a32b9d217","b095620f8f00421ab26f2549b27b11a4","cc682780d97e4f5aad492cf2153596b1","df8090dc2cd740d1ab9d890ce95f48e8","1d5d5d0788b349abae9e689bcd97462c","ac5a02de98b44382a5e348c35256b960","4276c3d65ea7487c841ad7eaf57df14f","8e72e50435b2478fb085155aa7efa34e","503ea6255fa64589806b9eb849a4b06f","af406d0fc6834d7fb03fc94b35e0a85a","f5a0f8138bb7425f99b9a47e4684be30","12ee3256d03a41d39200d6afb65645f7","23dfc585f74545a2b4e33a4e489979e3","6045b2d7a2254e6c8b84432e76bdb18c","29e89ea16fce4a7881a0f506c5164427","cc0c88fe2bb44d88bbf5a364d5ef2c22","c03baa4f082a4cc995f0ba5cfbaf0555","298d472a6f7b4b9bab2d544e264b213f"]},"executionInfo":{"status":"ok","timestamp":1677764100904,"user_tz":-60,"elapsed":4726,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"1cab6ef3-df89-4472-91ea-207dd999b20d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"885bb7cf41b843c0b8dd311a3470ea4f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e72e50435b2478fb085155aa7efa34e"}},"metadata":{}}]},{"cell_type":"markdown","source":["Load the IMDb dataset using pandas, and preprocess the text data by removing HTML tags, non-alphanumeric characters, and stop words."],"metadata":{"id":"Iw5Lk4nFXf1A"}},{"cell_type":"code","source":["print(imdb_dataset.column_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VoEDXTDQr89F","executionInfo":{"status":"ok","timestamp":1677766059808,"user_tz":-60,"elapsed":344,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"81172abb-8119-4838-c9f6-00e991092fe5"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["{'train': ['text', 'label'], 'test': ['text', 'label'], 'unsupervised': ['text', 'label']}\n"]}]},{"cell_type":"code","source":["# Load the IMDb dataset\n","imdb_train_df = pd.DataFrame(imdb_dataset['train'])\n","imdb_train_df = imdb_train_df.reset_index(drop=True)\n","imdb_test_df = pd.DataFrame(imdb_dataset['test'])\n","imdb_test_df = imdb_test_df.reset_index(drop=True)\n","\n","print('\\nIMDB data loaded:')\n","print('train:', imdb_train_df.shape)\n","print('test:', imdb_test_df.shape)\n","print(imdb_train_df['label'].unique())\n","print(imdb_test_df['label'].unique())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXioOoLXj5_6","executionInfo":{"status":"ok","timestamp":1677766067683,"user_tz":-60,"elapsed":4007,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"e2b49886-09d7-4aaf-f7ba-de30358336a5"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","IMDB data loaded:\n","train: (25000, 2)\n","test: (25000, 2)\n","[0 1]\n","[0 1]\n"]}]},{"cell_type":"code","source":["# Let's view some random reviews:\n","print(imdb_train_df.sample(5))\n","print(imdb_test_df.sample(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8beC0EPC_EH","executionInfo":{"status":"ok","timestamp":1677766073391,"user_tz":-60,"elapsed":229,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"4c7c7de1-d136-44e8-9c83-4927dfa30ec8"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                    text  label\n","1676   It Could Have Been A Marvelous Story Based On ...      0\n","15892  As with all environmentally aware films from t...      1\n","17981  This is one of the best of the genre. I saw it...      1\n","10490  This is one of those films that I could only s...      0\n","22783  Outragously entertaining period piece set in t...      1\n","                                                    text  label\n","23595  This film is worthwhile despite what you may h...      1\n","6000   This movie could have been oh so much better. ...      0\n","6183   like in so many movies of the past, you would ...      0\n","22590  Maybe I'm reading into this too much, but I wo...      1\n","5293   I was duped into watching this by the many fri...      0\n"]}]},{"cell_type":"code","source":["# Preprocess the text data\n","imdb_train_df ['text'] = imdb_train_df ['text'].str.replace('<.*?>', '', regex=True) # remove HTML tags\n","imdb_train_df ['text'] = imdb_train_df ['text'].str.replace('[^a-zA-Z0-9\\s]', '', regex=True) # remove non-alphanumeric characters\n","stop_words = set(stopwords.words('english'))\n","imdb_train_df ['text'] = imdb_train_df ['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words])) # remove stop words\n","\n","\n","imdb_test_df ['text'] = imdb_test_df ['text'].str.replace('<.*?>', '', regex=True) # remove HTML tags\n","imdb_train_df ['text'] = imdb_test_df ['text'].str.replace('[^a-zA-Z0-9\\s]', '', regex=True) # remove non-alphanumeric characters\n","stop_words = set(stopwords.words('english'))\n","imdb_test_df ['text'] = imdb_test_df ['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words])) # remove stop words"],"metadata":{"id":"CnXuWZ8HXzqY","executionInfo":{"status":"ok","timestamp":1677766082435,"user_tz":-60,"elapsed":4541,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["Load the SST-2 dataset using pandas, and preprocess the text data in the same way as the IMDb dataset"],"metadata":{"id":"M5ajmdUSTPKj"}},{"cell_type":"code","source":["print(sst2_dataset.column_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPKsg4shr4zn","executionInfo":{"status":"ok","timestamp":1677766084874,"user_tz":-60,"elapsed":224,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"641eea3b-f660-4725-e65d-a7636a806044"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["{'train': ['sentence', 'label', 'idx'], 'validation': ['sentence', 'label', 'idx'], 'test': ['sentence', 'label', 'idx']}\n"]}]},{"cell_type":"code","source":["# Load the SST-2 dataset\n","sst2_train_df = pd.DataFrame(sst2_dataset['train'])[['sentence', 'label']]\n","sst2_train_df = sst2_train_df.rename(columns={'sentence': 'text'})\n","sst2_train_df = sst2_train_df.reset_index(drop=True)\n","\n","sst2_test_df = pd.DataFrame(sst2_dataset['validation'])[['sentence', 'label']]\n","sst2_test_df = sst2_test_df.rename(columns={'sentence': 'text'})\n","sst2_test_df = sst2_test_df.reset_index(drop=True)\n","\n","#sst2_test_df =pd.concat([pd.DataFrame(sst2_dataset['test'])[['sentence', 'label']], pd.DataFrame(sst2_dataset['validation'])[['sentence', 'label']]])\n","\n","print('\\nSST2 data loaded:')\n","print('train:', sst2_train_df.shape)\n","print('test:', sst2_test_df.shape)\n","print(sst2_train_df['label'].unique())\n","print(sst2_test_df['label'].unique())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0sHU-_OllRtQ","executionInfo":{"status":"ok","timestamp":1677766262049,"user_tz":-60,"elapsed":7594,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"cc95f838-8241-4e2b-90be-89f499a7cf4a"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","SST2 data loaded:\n","train: (67349, 2)\n","test: (872, 2)\n","[0 1]\n","[1 0]\n"]}]},{"cell_type":"markdown","source":["Unbalanced set. Replace default split by train_test_split"],"metadata":{"id":"KSS15bBzr0lN"}},{"cell_type":"code","source":["# Load your dataframe\n","df = pd.concat([sst2_train_df,sst2_test_df])\n","\n","# Define your features and target variable\n","X = df.drop(\"label\", axis=1)\n","y = df[\"label\"]\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Check the shape of the train and test sets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)\n","\n","sst2_train_df = pd.concat([X_train,y_train], axis=1)\n","sst2_test_df = pd.concat([X_test,y_test], axis=1)\n","\n","print('\\nSST2 data re splitted:')\n","print('train:', sst2_train_df.shape)\n","print('test:', sst2_test_df.shape)\n","print(sst2_train_df['label'].unique())\n","print(sst2_test_df['label'].unique())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trDNhh0nsDGL","executionInfo":{"status":"ok","timestamp":1677767103663,"user_tz":-60,"elapsed":234,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"7f15f72d-f422-4626-b72a-7df6f70375d1"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (54576, 1)\n","X_test shape: (13645, 1)\n","y_train shape: (54576,)\n","y_test shape: (13645,)\n","\n","SST2 data re splitted:\n","train: (54576, 2)\n","test: (13645, 2)\n","[1 0]\n","[1 0]\n"]}]},{"cell_type":"code","source":["# Let's view some random reviews:\n","print(sst2_train_df.sample(5))\n","print(sst2_test_df.sample(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnTy7rj631jm","executionInfo":{"status":"ok","timestamp":1677767122410,"user_tz":-60,"elapsed":304,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"f39c6668-94a1-4d20-82cc-5b2469f653a3"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                    text  label\n","3689                        is far from disappointing ,       1\n","1910   not quite as miraculous as its dreamworks make...      1\n","45776                 fails to spark this leaden comedy       0\n","34412  are jarring and deeply out of place in what co...      0\n","41125                                   often funny way       1\n","                                                    text  label\n","25722                   is the central flaw of the film       0\n","52315         is a likable story , told with competence       1\n","36042  robinson 's web of suspense matches the page-t...      1\n","38595  we 're touched by the film 's conviction that ...      1\n","13970        flat-out amusing , sometimes endearing and       1\n"]}]},{"cell_type":"code","source":["# Preprocess the text data\n","sst2_train_df['text'] = sst2_train_df['text'].str.replace('<.*?>', '', regex=True) # remove HTML tags\n","sst2_train_df['text'] = sst2_train_df['text'].str.replace('[^a-zA-Z0-9\\s]', '', regex=True) # remove non-alphanumeric characters\n","stop_words = set(stopwords.words('english'))\n","sst2_train_df['text'] = sst2_train_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words])) # remove stop words\n","\n","\n","sst2_test_df['text'] = sst2_test_df['text'].str.replace('<.*?>', '', regex=True) # remove HTML tags\n","sst2_test_df['text'] = sst2_test_df['text'].str.replace('[^a-zA-Z0-9\\s]', '', regex=True) # remove non-alphanumeric characters\n","stop_words = set(stopwords.words('english'))\n","sst2_test_df['text'] = sst2_test_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words])) # remove stop words\n"],"metadata":{"id":"2z08oQ6aTPi5","executionInfo":{"status":"ok","timestamp":1677767206700,"user_tz":-60,"elapsed":581,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["Training and testing on SST2, OOD detection on IMDB"],"metadata":{"id":"KnVplK7CuFem"}},{"cell_type":"code","source":["train_df = sst2_train_df\n","test_df = sst2_test_df\n","ood_df = pd.concat([imdb_train_df,imdb_test_df])\n","ood_df = ood_df.reset_index(drop=True)"],"metadata":{"id":"stJtXnEyuE5h","executionInfo":{"status":"ok","timestamp":1677767459145,"user_tz":-60,"elapsed":229,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# Let's view some random reviews:\n","print(train_df.sample(5))\n","print(test_df.sample(5))\n","print(ood_df.sample(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tP31G-YOvAMp","executionInfo":{"status":"ok","timestamp":1677767498573,"user_tz":-60,"elapsed":254,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"9c305e7c-e9de-4173-c9ad-d17084fa7dbb"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                    text  label\n","50861                     quietly introspective portrait      1\n","7668            skip film buy philip glass soundtrack cd      0\n","1626                   seem long two year affair subject      0\n","2230                          unsung heroes 20th century      1\n","11261  thirteen conversations one thing generosity op...      1\n","                                                    text  label\n","4364      begrudge anyone receiving whatever consolation      0\n","41834        obvious copy one best films ever made could      0\n","36204                                         love power      1\n","51557                                    though much fun      1\n","55263  subtitled costume drama set remote african emp...      1\n","                                                    text  label\n","37258  It's long time ago I saw movie still one worst...      0\n","43201  As kid I loved song \"Never smile crocodile\", I...      1\n","388    Lets see What annoyed me most The extra long d...      0\n","13225  Beware My Lovely is an experimental studio fil...      1\n","45385  Clint Eastwood plays wounded Union soldier fou...      1\n"]}]},{"cell_type":"markdown","source":["The token `[CLS]` is a special token required by BERT at the beginning of the sentence."],"metadata":{"id":"1ZuRWQHKTbVn"}},{"cell_type":"code","source":["sentences_train = train_df.text.values\n","sentences_train = [\"[CLS] \" + s for s in sentences_train]\n","\n","sentences_test = test_df.text.values\n","sentences_test = [\"[CLS] \" + s for s in sentences_test]\n","\n","sentences_ood = ood_df.text.values\n","sentences_ood = [\"[CLS] \" + s for s in sentences_ood]\n","\n","\n","labels_train = train_df.label.values\n","labels_test  = test_df.label.values\n","labels_ood  = ood_df.label.values\n","\n","print (\"\\nThe first training sentence:\")\n","print(sentences_train[0], 'LABEL:', labels_train[0])\n"],"metadata":{"id":"UPKOd23EMA5h","executionInfo":{"status":"ok","timestamp":1677767514951,"user_tz":-60,"elapsed":214,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3da0d3e-4086-4da4-e59e-c585714f4bf4"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The first training sentence:\n","[CLS] wildly alive LABEL: 1\n"]}]},{"cell_type":"markdown","source":["Next we use the BERT tokenizer to convert the sentences into tokens\n","that match the data BERT was trained on.\n"],"metadata":{"id":"71yBR1tYTeFz"}},{"cell_type":"code","source":["BERTMODEL = \"bert-base-uncased\"\n","\n","tokenizer = BertTokenizer.from_pretrained(BERTMODEL,\n","                                          do_lower_case=True)\n","\n","tokenized_train = [tokenizer.tokenize(s) for s in sentences_train]\n","tokenized_test  = [tokenizer.tokenize(s) for s in sentences_test]\n","tokenized_ood  = [tokenizer.tokenize(s) for s in sentences_ood]\n","\n","print (\"\\nThe full tokenized first training sentence:\")\n","print (tokenized_train[0])\n","\n","print (\"\\nThe full tokenized first test sentence:\")\n","print (tokenized_test[0])\n","\n","print (\"\\nThe full tokenized first OOD sentence:\")\n","print (tokenized_ood[0])"],"metadata":{"id":"_pTzOWtWTe0w","executionInfo":{"status":"ok","timestamp":1677767912423,"user_tz":-60,"elapsed":360085,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"931f449e-c311-4c98-c6f3-6428d495c038"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 231508/231508 [00:00<00:00, 1224484.43B/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","The full tokenized first training sentence:\n","['[CLS]', 'wildly', 'alive']\n"]}]},{"cell_type":"markdown","source":["\n","Now we set the maximum sequence lengths for our training and test\n","sentences as `MAX_LEN_TRAIN` and `MAX_LEN_TEST`. The maximum length\n","supported by the used BERT model is 512.\n","\n","The token `[SEP]` is another special token required by BERT at the\n","end of the sentence.\n","\n","#TO DO OOD detection !!"],"metadata":{"id":"iGEGsXZLThMZ"}},{"cell_type":"code","source":["MAX_LEN_TRAIN, MAX_LEN_TEST = 128, 512\n","\n","tokenized_train = [t[:(MAX_LEN_TRAIN-1)]+['SEP'] for t in tokenized_train]\n","tokenized_test  = [t[:(MAX_LEN_TEST-1)]+['SEP'] for t in tokenized_test]\n","\n","print (\"\\nThe truncated tokenized first training sentence:\")\n","print (tokenized_train[0])"],"metadata":{"id":"YxtWll1wThtk","colab":{"base_uri":"https://localhost:8080/","height":92},"executionInfo":{"status":"ok","timestamp":1677708169998,"user_tz":-60,"elapsed":437,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"5547c585-c568-4257-d461-8102c0d49c5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The truncated tokenized first training sentence:\n","['[CLS]', 'i', 'love', 'sci', '##fi', 'and', 'am', 'willing', 'to', 'put', 'up', 'with', 'a', 'lot', 'sci', '##fi', 'movies', '##tv', 'are', 'usually', 'under', '##fu', '##nded', 'under', '##app', '##re', '##cia', '##ted', 'and', 'misunderstood', 'i', 'tried', 'to', 'like', 'this', 'i', 'really', 'did', 'but', 'it', 'is', 'to', 'good', 'tv', 'sci', '##fi', 'as', 'babylon', '5', 'is', 'to', 'star', 'trek', 'the', 'original', 'silly', 'pro', '##st', '##hetic', '##s', 'cheap', 'cardboard', 'sets', 'stil', '##ted', 'dialogues', 'c', '##g', 'that', 'doesn', '##t', 'match', 'the', 'background', 'and', 'painfully', 'one', '##dim', '##ens', '##ional', 'characters', 'cannot', 'be', 'overcome', 'with', 'a', 'sci', '##fi', 'setting', 'im', 'sure', 'there', 'are', 'those', 'of', 'you', 'out', 'there', 'who', 'think', 'babylon', '5', 'is', 'good', 'sci', '##fi', 'tv', 'its', 'not', 'its', 'cl', '##ich', '##d', 'and', 'un', '##ins', '##pi', '##ring', 'while', 'us', 'viewers', 'might', 'like', 'emotion', 'and', 'character', 'development', 'SEP']\n"]}]},{"cell_type":"markdown","source":["\n","Next we use the BERT tokenizer to convert each token into an integer\n","index in the BERT vocabulary. We also pad any shorter sequences to\n","`MAX_LEN_TRAIN` or `MAX_LEN_TEST` indices with trailing zeros."],"metadata":{"id":"2FDmuiZ5VaOQ"}},{"cell_type":"code","source":["ids_train = [tokenizer.convert_tokens_to_ids(t) for t in tokenized_train]\n","ids_train = np.array([np.pad(i, (0, MAX_LEN_TRAIN-len(i)),\n","                             mode='constant') for i in ids_train])\n","\n","ids_test = [tokenizer.convert_tokens_to_ids(t) for t in tokenized_test]\n","ids_test = np.array([np.pad(i, (0, MAX_LEN_TEST-len(i)),\n","                            mode='constant') for i in ids_test])\n","\n","print (\"\\nThe indices of the first training sentence:\")\n","print (ids_train[0])"],"metadata":{"id":"H0LgugShVasR","executionInfo":{"status":"ok","timestamp":1677708190745,"user_tz":-60,"elapsed":17716,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d3cfa8ad-8ae7-407e-83a2-467ce1348a25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The indices of the first training sentence:\n","[  101  1045  2293 16596  8873  1998  2572  5627  2000  2404  2039  2007\n","  1037  2843 16596  8873  5691  9189  2024  2788  2104 11263 25848  2104\n"," 29098  2890  7405  3064  1998 28947  1045  2699  2000  2066  2023  1045\n","  2428  2106  2021  2009  2003  2000  2204  2694 16596  8873  2004 17690\n","  1019  2003  2000  2732 10313  1996  2434 10021  4013  3367 20086  2015\n"," 10036 19747  4520 25931  3064 22580  1039  2290  2008  2987  2102  2674\n","  1996  4281  1998 16267  2028 22172  6132 19301  3494  3685  2022  9462\n","  2007  1037 16596  8873  4292 10047  2469  2045  2024  2216  1997  2017\n","  2041  2045  2040  2228 17690  1019  2003  2204 16596  8873  2694  2049\n","  2025  2049 18856  7033  2094  1998  4895  7076  8197  4892  2096  2149\n","  7193  2453  2066  7603  1998  2839  2458   100]\n"]}]},{"cell_type":"markdown","source":["BERT also requires *attention masks*, with 1 for each real token in\n","the sequences and 0 for the padding:"],"metadata":{"id":"KXHXkvs5JTet"}},{"cell_type":"code","source":["amasks_train, amasks_test = [], []\n","\n","for seq in ids_train:\n","  seq_mask = [float(i>0) for i in seq]\n","  amasks_train.append(seq_mask)\n","\n","for seq in ids_test:\n","  seq_mask = [float(i>0) for i in seq]\n","  amasks_test.append(seq_mask)"],"metadata":{"id":"2yaiNP45Dkcm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We use scikit-learn's train_test_split() to use 10% of our training\n","data as a validation set, and then convert all data into\n","torch.tensors."],"metadata":{"id":"Ko7iCp5cJiyd"}},{"cell_type":"code","source":["(train_inputs, validation_inputs,\n"," train_labels, validation_labels) = train_test_split(ids_train, labels_train,\n","                                                     random_state=42,\n","                                                     test_size=0.1)\n","(train_masks, validation_masks,\n"," _, _) = train_test_split(amasks_train, ids_train,\n","                          random_state=42, test_size=0.1)\n","\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks  = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks  = torch.tensor(validation_masks)\n","test_inputs = torch.tensor(ids_test)\n","test_labels = torch.tensor(labels_test)\n","test_masks  = torch.tensor(amasks_test)\n"],"metadata":{"id":"p3djaDPDJnZ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next we create PyTorch *DataLoader*s for all data sets.\n","For fine-tuning BERT on a specific task, the authors recommend a\n","batch size of 16 or 32."],"metadata":{"id":"a4TDX7VtJ2aA"}},{"cell_type":"code","source":["BATCH_SIZE = 32\n","\n","print('\\nDatasets:')\n","print('Train: ', end=\"\")\n","train_data = TensorDataset(train_inputs, train_masks,\n","                           train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler,\n","                              batch_size=BATCH_SIZE)\n","print(len(train_data), 'reviews')\n","\n","print('Validation: ', end=\"\")\n","validation_data = TensorDataset(validation_inputs, validation_masks,\n","                                validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data,\n","                                   sampler=validation_sampler,\n","                                   batch_size=BATCH_SIZE)\n","print(len(validation_data), 'reviews')\n","\n","print('Test: ', end=\"\")\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler,\n","                             batch_size=BATCH_SIZE)\n","print(len(test_data), 'reviews')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AjgT4K4J2Fv","executionInfo":{"status":"ok","timestamp":1677708213825,"user_tz":-60,"elapsed":382,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"2b967838-f6ea-4b78-eec4-b5a1ae6667d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Datasets:\n","Train: 22500 reviews\n","Validation: 2500 reviews\n","Test: 25000 reviews\n"]}]},{"cell_type":"markdown","source":["BERT MODEL INITIALIZATION\n","\n","We now load a pretrained BERT model with a single linear\n","classification layer added on top.\n"],"metadata":{"id":"a4Wi5wQqKEuc"}},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(BERTMODEL,\n","                                                      num_labels=2)\n","\n","model.cuda()\n","print('\\nPretrained BERT model \"{}\" loaded'.format(BERTMODEL))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdIeyBLOJ2DE","executionInfo":{"status":"ok","timestamp":1677708271732,"user_tz":-60,"elapsed":52315,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"21899baa-1fe7-4996-c013-494b260909d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 433/433 [00:00<00:00, 90584.75B/s]\n","100%|██████████| 440473133/440473133 [00:38<00:00, 11553603.76B/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Pretrained BERT model \"bert-base-uncased\" loaded\n"]}]},{"cell_type":"markdown","source":["\n","We set the remaining hyperparameters needed for fine-tuning the\n","pretrained model: \n"," * EPOCHS: the number of training epochs in fine-tuning\n","   (recommended values between 2 and 4) \n"," * WEIGHT_DECAY: weight decay for the Adam optimizer \n"," * LR: learning rate for the Adam optimizer \n","   (2e-5 to 5e-5 recommended) \n"," * WARMUP_STEPS: number of warmup steps to (linearly) reach the\n","   set learning rate\n","\n"," We also need to grab the training parameters from the pretrained\n"," model."],"metadata":{"id":"ynTgfHzeLUXY"}},{"cell_type":"code","source":["EPOCHS = 4\n","WEIGHT_DECAY = 0.01\n","LR = 2e-5\n","WARMUP_STEPS =int(0.2*len(train_dataloader))\n","\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters()\n","                if not any(nd in n for nd in no_decay)],\n","     'weight_decay': WEIGHT_DECAY},\n","    {'params': [p for n, p in model.named_parameters()\n","                if any(nd in n for nd in no_decay)],\n","     'weight_decay': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LR, eps=1e-8)\n","scheduler = WarmupLinearSchedule(optimizer, warmup_steps=WARMUP_STEPS,\n","                                 t_total=len(train_dataloader)*EPOCHS)"],"metadata":{"id":"ZSPy9RhsJ2AT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LEARNING\n","\n","Let's now define functions to train() and evaluate() the model:"],"metadata":{"id":"zpTM0QR9Lyee"}},{"cell_type":"code","source":["def train(epoch, loss_vector=None, log_interval=200):\n","  # Set model to training mode\n","  model.train()\n","\n","  # Loop over each batch from the training set\n","  for step, batch in enumerate(train_dataloader):\n","\n","    # Copy data to GPU if needed\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    # Zero gradient buffers\n","    optimizer.zero_grad()\n","\n","    # Forward pass\n","    outputs = model(b_input_ids, token_type_ids=None,\n","                    attention_mask=b_input_mask, labels=b_labels)\n","\n","    loss = outputs[0]\n","    if loss_vector is not None:\n","        loss_vector.append(loss.item())\n","\n","    # Backward pass\n","    loss.backward()\n","\n","    # Update weights\n","    scheduler.step()\n","    optimizer.step()\n","\n","    if step % log_interval == 0:\n","        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, step * len(b_input_ids),\n","                len(train_dataloader.dataset),\n","                100. * step / len(train_dataloader), loss))\n","\n","def evaluate(loader):\n","  model.eval()\n","\n","  n_correct, n_all = 0, 0\n","\n","  for batch in loader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None,\n","                      attention_mask=b_input_mask)\n","      logits = outputs[0]\n","\n","    logits = logits.detach().cpu().numpy()\n","    predictions = np.argmax(logits, axis=1)\n","\n","    labels = b_labels.to('cpu').numpy()\n","    n_correct += np.sum(predictions == labels)\n","    n_all += len(labels)\n","\n","  print('Accuracy: [{}/{}] {:.4f}'.format(n_correct, n_all,\n","                                          n_correct/n_all))"],"metadata":{"id":"mr73s5_dJ19k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we are ready to train our model using the train()\n","function. After each epoch, we evaluate the model using the\n","validation set and evaluate()."],"metadata":{"id":"FMuuXi6lL65Q"}},{"cell_type":"code","source":["train_lossv = []\n","for epoch in range(1, EPOCHS + 1):\n","    print()\n","    train(epoch, train_lossv)\n","    print('\\nValidation set:')\n","    evaluate(validation_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-TeGUafJ16j","executionInfo":{"status":"ok","timestamp":1677713348266,"user_tz":-60,"elapsed":2080861,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"69fd41ca-19d9-4bd7-a56b-06eece3ce983"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Train Epoch: 1 [0/22500 (0%)]\tLoss: 0.024794\n","Train Epoch: 1 [6400/22500 (28%)]\tLoss: 0.005147\n","Train Epoch: 1 [12800/22500 (57%)]\tLoss: 0.006284\n","Train Epoch: 1 [19200/22500 (85%)]\tLoss: 0.007105\n","\n","Validation set:\n","Accuracy: [2245/2500] 0.8980\n","\n","Train Epoch: 2 [0/22500 (0%)]\tLoss: 0.019169\n","Train Epoch: 2 [6400/22500 (28%)]\tLoss: 0.009380\n","Train Epoch: 2 [12800/22500 (57%)]\tLoss: 0.162212\n","Train Epoch: 2 [19200/22500 (85%)]\tLoss: 0.010926\n","\n","Validation set:\n","Accuracy: [2245/2500] 0.8980\n","\n","Train Epoch: 3 [0/22500 (0%)]\tLoss: 0.160825\n","Train Epoch: 3 [6400/22500 (28%)]\tLoss: 0.007826\n","Train Epoch: 3 [12800/22500 (57%)]\tLoss: 0.003743\n","Train Epoch: 3 [19200/22500 (85%)]\tLoss: 0.049098\n","\n","Validation set:\n","Accuracy: [2245/2500] 0.8980\n","\n","Train Epoch: 4 [0/22500 (0%)]\tLoss: 0.023789\n","Train Epoch: 4 [6400/22500 (28%)]\tLoss: 0.004843\n","Train Epoch: 4 [12800/22500 (57%)]\tLoss: 0.013440\n","Train Epoch: 4 [19200/22500 (85%)]\tLoss: 0.014888\n","\n","Validation set:\n","Accuracy: [2245/2500] 0.8980\n"]}]},{"cell_type":"markdown","source":["Let's take a look at our training loss over all batches:"],"metadata":{"id":"RbJJCz8GMDt1"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(15,8))\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Batch\")\n","plt.ylabel(\"Loss\")\n","plt.plot(train_lossv, label='original')\n","plt.plot(np.convolve(train_lossv, np.ones(101), 'same') / 101,\n","         label='averaged')\n","plt.legend(loc='best')\n","plt.savefig(\"training-loss.png\")\n","plt.show()\n"],"metadata":{"id":"YehHezB-J13b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Inference\n","\n","For a better measure of the quality of the model, let's see the\n","model accuracy for the test reviews."],"metadata":{"id":"cZ60h-XMMQcK"}},{"cell_type":"code","source":["print('\\nTest set:')\n","evaluate(test_dataloader)\n","\n","# eof"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoW9yYglJ1vs","executionInfo":{"status":"ok","timestamp":1677714864839,"user_tz":-60,"elapsed":872574,"user":{"displayName":"Andres Fernando Garcia Parrado","userId":"07689739672482382229"}},"outputId":"7a8443b6-fbd7-4c71-b7cc-64e361a01b70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set:\n","Accuracy: [22972/25000] 0.9189\n"]}]},{"cell_type":"markdown","source":["Once training is complete, we can evaluate the model on the SST2 dataset:"],"metadata":{"id":"LUZRDtcEE2lo"}},{"cell_type":"markdown","source":["Finally, we'll save the hidden layers and trained values of the model:\n","#TO DO"],"metadata":{"id":"cMGqokSwFArh"}},{"cell_type":"code","source":["# Save hidden layers and trained values\n","torch.save({\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict(),\n","    'scheduler_state_dict': scheduler.state_dict(),\n","    'hidden_layers': model.encoder.layer[-1].output_hidden_states,\n","    'trained_values': model.pooler.dense.weight\n","}, 'path/to/save/model.pt')\n"],"metadata":{"id":"3FYgHg9xFBDF"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1W6mUzJV-FZrp4gV_Cquq8jm9Qw3ZhyTU","authorship_tag":"ABX9TyNUyS0+ENUGFZ6nL5XH4GXQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"885bb7cf41b843c0b8dd311a3470ea4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bb2fcc4a11f4318b170136d08ed8859","IPY_MODEL_023d392d1eb740c68f9147860f900d14","IPY_MODEL_9e9558b7ff0d419580512e75b0cd71c5"],"layout":"IPY_MODEL_36c69c1186404946861e9e5a32b9d217"}},"7bb2fcc4a11f4318b170136d08ed8859":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b095620f8f00421ab26f2549b27b11a4","placeholder":"​","style":"IPY_MODEL_cc682780d97e4f5aad492cf2153596b1","value":"100%"}},"023d392d1eb740c68f9147860f900d14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8090dc2cd740d1ab9d890ce95f48e8","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d5d5d0788b349abae9e689bcd97462c","value":3}},"9e9558b7ff0d419580512e75b0cd71c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac5a02de98b44382a5e348c35256b960","placeholder":"​","style":"IPY_MODEL_4276c3d65ea7487c841ad7eaf57df14f","value":" 3/3 [00:00&lt;00:00, 46.63it/s]"}},"36c69c1186404946861e9e5a32b9d217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b095620f8f00421ab26f2549b27b11a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc682780d97e4f5aad492cf2153596b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df8090dc2cd740d1ab9d890ce95f48e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d5d5d0788b349abae9e689bcd97462c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac5a02de98b44382a5e348c35256b960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4276c3d65ea7487c841ad7eaf57df14f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e72e50435b2478fb085155aa7efa34e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_503ea6255fa64589806b9eb849a4b06f","IPY_MODEL_af406d0fc6834d7fb03fc94b35e0a85a","IPY_MODEL_f5a0f8138bb7425f99b9a47e4684be30"],"layout":"IPY_MODEL_12ee3256d03a41d39200d6afb65645f7"}},"503ea6255fa64589806b9eb849a4b06f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23dfc585f74545a2b4e33a4e489979e3","placeholder":"​","style":"IPY_MODEL_6045b2d7a2254e6c8b84432e76bdb18c","value":"100%"}},"af406d0fc6834d7fb03fc94b35e0a85a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29e89ea16fce4a7881a0f506c5164427","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc0c88fe2bb44d88bbf5a364d5ef2c22","value":3}},"f5a0f8138bb7425f99b9a47e4684be30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c03baa4f082a4cc995f0ba5cfbaf0555","placeholder":"​","style":"IPY_MODEL_298d472a6f7b4b9bab2d544e264b213f","value":" 3/3 [00:00&lt;00:00, 58.41it/s]"}},"12ee3256d03a41d39200d6afb65645f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23dfc585f74545a2b4e33a4e489979e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6045b2d7a2254e6c8b84432e76bdb18c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29e89ea16fce4a7881a0f506c5164427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc0c88fe2bb44d88bbf5a364d5ef2c22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c03baa4f082a4cc995f0ba5cfbaf0555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"298d472a6f7b4b9bab2d544e264b213f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}